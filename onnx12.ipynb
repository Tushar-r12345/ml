{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2edd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Input: [[1. 2. 3.]]\n",
      "Weights: [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Bias: [ 1. -1.]\n",
      "Output: [[15. 31.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx as onnx\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple linear transformation module\n",
    "class LinearTransform(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearTransform, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.tensor([1.0, -1.0], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.matmul(input, self.weights.t()) + self.bias\n",
    "\n",
    "# Create an instance of the linear transformation module\n",
    "linear_model = LinearTransform(input_dim=3, output_dim=2)\n",
    "\n",
    "# Create an example input tensor\n",
    "input_data = torch.tensor([[1.0, 2.0, 3.0]], dtype=torch.float32)\n",
    "\n",
    "# Execute the linear transformation\n",
    "output_data = linear_model(input_data)\n",
    "\n",
    "# Save the model as ONNX\n",
    "onnx_path = \"single_layer_model.onnx\"\n",
    "torch.onnx.export(linear_model, input_data, onnx_path)\n",
    "\n",
    "# Convert the output tensor to a NumPy array\n",
    "output_np = output_data.detach().numpy()\n",
    "\n",
    "# Print the output\n",
    "print(\"Input:\", input_data.numpy())\n",
    "print(\"Weights:\", linear_model.weights.detach().numpy())\n",
    "print(\"Bias:\", linear_model.bias.detach().numpy())\n",
    "print(\"Output:\", output_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ce3880",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Required inputs (['onnx::MatMul_0']) are missing from input feed (['input']).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run the inference\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get the output tensor\u001b[39;00m\n\u001b[0;32m     15\u001b[0m output_data \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\anacondawala\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:213\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_names, input_feed, run_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Compute the predictions.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m        sess.run([output_name], {input_name: x})\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_feed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_names:\n\u001b[0;32m    215\u001b[0m         output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n",
      "File \u001b[1;32mD:\\anacondawala\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:195\u001b[0m, in \u001b[0;36mSession._validate_input\u001b[1;34m(self, feed_input_names)\u001b[0m\n\u001b[0;32m    193\u001b[0m         missing_input_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_input_names:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequired inputs (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_input_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) are missing from input feed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeed_input_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Required inputs (['onnx::MatMul_0']) are missing from input feed (['input'])."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_path = \"single_layer_model.onnx\"\n",
    "sess = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.array([[1.0, 2.0, 3.0]], dtype=np.float32)\n",
    "\n",
    "# Run the inference\n",
    "output = sess.run(None, {'input': input_data})\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = output[0]\n",
    "\n",
    "# Print the output\n",
    "print(\"Input:\", input_data)\n",
    "print(\"Output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d75c188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor names: ['onnx::MatMul_0']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_path = \"single_layer_model.onnx\"\n",
    "sess = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# Print the input tensor names\n",
    "input_names = [input_.name for input_ in sess.get_inputs()]\n",
    "print(\"Input tensor names:\", input_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aef58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[1. 2. 3.]]\n",
      "Output: [[15. 31.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_path = \"single_layer_model.onnx\"\n",
    "sess = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.array([[1.0, 2.0, 3.0]], dtype=np.float32)\n",
    "\n",
    "# Run the inference\n",
    "output = sess.run(None, {'onnx::MatMul_0': input_data})\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = output[0]\n",
    "\n",
    "# Print the output\n",
    "print(\"Input:\", input_data)\n",
    "print(\"Output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bfae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
